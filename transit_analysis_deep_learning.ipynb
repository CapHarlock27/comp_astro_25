{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "71bwy0C6Zjs9",
      "metadata": {
        "id": "71bwy0C6Zjs9"
      },
      "source": [
        "# Final TESS Transit Classification — Optimized for Extreme Class Imbalance\n",
        "\n",
        "This notebook converts and expands the provided Python script into a fully documented, didactic, and **step-by-step** workflow.\n",
        "We train a 1D CNN to classify TESS light curves into *transit* (planet candidate) vs *non-transit* under **severe class imbalance**.\n",
        "\n",
        "**Key strategies covered:**\n",
        "\n",
        "- **Balanced augmentation** (equal samples per class) to mitigate imbalance during training.  \n",
        "- **Focal loss** (tunable `gamma` and `alpha`) to emphasize hard examples and rare positives.  \n",
        "- **Threshold optimization** using **Youden’s J** from the ROC curve (don’t use the default 0.5).  \n",
        "- **Simplified CNN architecture** to reduce overfitting.  \n",
        "- **AUC-centric monitoring** with early stopping and LR scheduling.\n",
        "\n",
        "> **What you’ll learn**\n",
        ">\n",
        "> 1. Why balanced training batches help under extreme imbalance.  \n",
        "> 2. How focal loss reshapes the gradient to focus on hard/rare samples.  \n",
        "> 3. How to pick a **data-driven** decision threshold that best trades off TPR/FPR.  \n",
        "> 4. How to evaluate with AUC-ROC rather than accuracy (which can be misleading).  \n",
        "> 5. How to visualize confusion matrices and sample light curves with predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KL8PnzMkZjtD",
      "metadata": {
        "id": "KL8PnzMkZjtD"
      },
      "source": [
        "## 1. Prerequisites & Data\n",
        "\n",
        "**Dependencies** (install if needed):\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn matplotlib tensorflow\n",
        "```\n",
        "\n",
        "> We intentionally avoid additional plotting libraries to keep dependencies compact.  \n",
        "> If you already have a working scientific Python/TensorFlow stack, you can skip installations.\n",
        "\n",
        "**Expected dataset**: a CSV file named **`tess_data.csv`** in the working directory with:\n",
        "\n",
        "- **Light-curve samples**: `flux_0000, flux_0001, ..., flux_0999` (or up to `n_bins-1`)  \n",
        "- **Flux uncertainties**: `flux_err_0000, ..., flux_err_0999`  \n",
        "- **Label**: `label` (0 = Non-Planet, 1 = Planet)  \n",
        "- **Metadata** (used for plots/titles): `toi_name, tic, disp, period_d, t0_bjd, dur_hr, sector`\n",
        "\n",
        "You can change the filename or number of bins via parameters in the **Data Loading** section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4rHajZUCZjtE",
      "metadata": {
        "id": "4rHajZUCZjtE"
      },
      "source": [
        "## 2. Environment Setup\n",
        "\n",
        "Set up imports, suppress noisy warnings, and fix seeds for reproducibility.  \n",
        "(Exact reproducibility on GPUs may still vary across hardware/driver versions.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "883a4745",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "883a4745",
        "outputId": "590b1dfc-d6b4-4dc0-9225-0e2c172edd3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting working directory to:  /ca25/comp_astro25\n",
            "None\n",
            "======================================================================\n",
            "FINAL TESS CLASSIFICATION\n",
            "======================================================================\n",
            "TF version: 2.20.0\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import IPython\n",
        "    working_directory = \"/\".join(\n",
        "            IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[:-1]\n",
        "        )\n",
        "    print(\"Setting working directory to: \", working_directory)\n",
        "    print(os.chdir(working_directory))\n",
        "except Exception as e:\n",
        "    print(\"It was impossible to set your directory as the current one because of the following message\")\n",
        "    print(e)\n",
        "    print(\"The working directory is: \", os.getcwd())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(27)\n",
        "tf.random.set_seed(27)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL TESS CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Optional: make TF less eager to pre-allocate all GPU memory (if using GPU)\n",
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    if gpus:\n",
        "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
        "except Exception as e:\n",
        "    print(\"GPU setup note:\", e)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7201e4a1",
      "metadata": {
        "id": "7201e4a1"
      },
      "source": [
        "## 3. Focal Loss (for severe imbalance)\n",
        "\n",
        "**Why focal loss?** With extreme imbalance, the model can get “lazy”—it learns to do well by focusing on the majority class.  \n",
        "Focal loss down-weights *easy* examples and concentrates gradient on *hard* ones by adding a modulating factor \\((1 - p_t)^\\gamma\\).  \n",
        "We also use class weighting via \\(\\alpha\\) to up-weight the rare positive class.\n",
        "\n",
        "- **`gamma`** (focusing parameter): higher values put more emphasis on hard examples.  \n",
        "- **`alpha`** (class weight): weight for positive class (1); negative class gets \\(1 - \\alpha\\).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a2de8e26",
      "metadata": {
        "id": "a2de8e26"
      },
      "outputs": [],
      "source": [
        "def focal_loss(gamma=2.5, alpha=0.75):\n",
        "    \"\"\"Focal loss optimized for severe imbalance (binary).\"\"\"\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        alpha_factor = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        focal_weight = alpha_factor * K.pow(1 - pt, gamma)\n",
        "        bce = -K.log(pt)\n",
        "        return K.mean(focal_weight * bce)\n",
        "    return focal_loss_fixed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ae786d",
      "metadata": {
        "id": "85ae786d"
      },
      "source": [
        "## 4. Balanced Augmentation\n",
        "\n",
        "We **balance the training set** to a fixed number of samples per class.  \n",
        "If a class has too few samples, we create augmented variants (noise, scale, shift, combo).  \n",
        "This prevents the model from being swamped by the majority class during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "24800de1",
      "metadata": {
        "id": "24800de1"
      },
      "outputs": [],
      "source": [
        "def create_balanced_dataset(X, y, samples_per_class=400):\n",
        "    \"\"\"Create a perfectly balanced dataset via lightweight augmentations.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING BALANCED DATASET\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    X_class0 = X[y == 0]\n",
        "    X_class1 = X[y == 1]\n",
        "\n",
        "    print(f\"Original - Class 0: {len(X_class0)}, Class 1: {len(X_class1)}\")\n",
        "\n",
        "    def augment_to_target(X_orig, n_target):\n",
        "        if len(X_orig) >= n_target:\n",
        "            idx = np.random.choice(len(X_orig), n_target, replace=False)\n",
        "            return X_orig[idx]\n",
        "\n",
        "        X_result = [X_orig]\n",
        "        while len(np.vstack(X_result)) < n_target:\n",
        "            # number we still need (cap to avoid oversampling too big chunks)\n",
        "            n_needed = n_target - len(np.vstack(X_result))\n",
        "            idx = np.random.choice(len(X_orig), min(len(X_orig), n_needed))\n",
        "\n",
        "            aug_type = np.random.rand()\n",
        "            if aug_type < 0.25:\n",
        "                # Additive Gaussian noise\n",
        "                X_aug = X_orig[idx] + np.random.normal(0, 0.01, (len(idx), X_orig.shape[1]))\n",
        "            elif aug_type < 0.5:\n",
        "                # Multiplicative scaling\n",
        "                scale = 1.0 + np.random.uniform(-0.03, 0.03, (len(idx), 1))\n",
        "                X_aug = X_orig[idx] * scale\n",
        "            elif aug_type < 0.75:\n",
        "                # Circular shift (time shift)\n",
        "                shifts = np.random.randint(-20, 20, len(idx))\n",
        "                X_aug = np.array([np.roll(X_orig[i], s) for i, s in zip(idx, shifts)])\n",
        "            else:\n",
        "                # Mild combo: small scale + small noise\n",
        "                X_aug = X_orig[idx] * (1.0 + np.random.uniform(-0.02, 0.02, (len(idx), 1)))\n",
        "                X_aug += np.random.normal(0, 0.008, X_aug.shape)\n",
        "\n",
        "            X_result.append(X_aug)\n",
        "\n",
        "        X_final = np.vstack(X_result)\n",
        "        return X_final[:n_target]\n",
        "\n",
        "    X0_bal = augment_to_target(X_class0, samples_per_class)\n",
        "    X1_bal = augment_to_target(X_class1, samples_per_class)\n",
        "\n",
        "    print(f\"Balanced - Class 0: {len(X0_bal)}, Class 1: {len(X1_bal)}\")\n",
        "\n",
        "    X_balanced = np.vstack([X0_bal, X1_bal])\n",
        "    y_balanced = np.concatenate([np.zeros(samples_per_class), np.ones(samples_per_class)])\n",
        "\n",
        "    # Shuffle\n",
        "    idx = np.arange(len(X_balanced))\n",
        "    np.random.shuffle(idx)\n",
        "\n",
        "    return X_balanced[idx], y_balanced[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34555fb8",
      "metadata": {
        "id": "34555fb8"
      },
      "source": [
        "## 5. Data Loading, Splitting & Standardization\n",
        "\n",
        "We split **before** augmentation (to avoid leakage), then **balance only the training split**.  \n",
        "We standardize the flux (zero mean / unit variance) using statistics from the training set only.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- Error bars `X_err` are **not** standardized (kept in their original scale).  \n",
        "- We keep the **test metadata** to produce nicer titles in the sample light-curve plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "45df1a84",
      "metadata": {
        "id": "45df1a84"
      },
      "outputs": [],
      "source": [
        "def load_data(csv_path='tess_data.csv', n_bins=1000):\n",
        "    \"\"\"Load CSV, split, balance train set, and standardize features.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Dataset: {df.shape[0]} samples\")\n",
        "\n",
        "    flux_cols = [f'flux_{i:04d}' for i in range(n_bins)]\n",
        "    flux_err_cols = [f'flux_err_{i:04d}' for i in range(n_bins)]\n",
        "    X = df[flux_cols].values\n",
        "    X_err = df[flux_err_cols].values\n",
        "    y = df['label'].values\n",
        "\n",
        "    metadata_cols = ['toi_name', 'tic', 'label', 'disp', 'period_d', 't0_bjd', 'dur_hr', 'sector']\n",
        "    metadata = df[metadata_cols]\n",
        "\n",
        "    print(\"\\nOriginal distribution:\")\n",
        "    print(f\"  Class 0: {(y==0).sum()}, Class 1: {(y==1).sum()}\")\n",
        "    if (y==0).sum() > 0:\n",
        "        print(f\"  Ratio: {(y==1).sum() / (y==0).sum():.2f}:1\")\n",
        "\n",
        "    # Train/test split (keep errors aligned; stratify to preserve class ratio)\n",
        "    X_train, X_test, y_train, y_test, X_err_train, X_err_test, idx_train, idx_test = train_test_split(\n",
        "        X, y, X_err, np.arange(len(y)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"\\nInitial split - Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "\n",
        "    # Balance training set\n",
        "    X_train, y_train = create_balanced_dataset(X_train, y_train, samples_per_class=350)\n",
        "\n",
        "    # Standardize (fit on train, apply to test)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STANDARDIZATION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"Train: mean={X_train.mean():.6f}, std={X_train.std():.6f}\")\n",
        "    print(f\"Test:  mean={X_test.mean():.6f}, std={X_test.std():.6f}\")\n",
        "\n",
        "    # Reshape for Conv1D: (samples, timesteps, channels)\n",
        "    X_train = X_train.reshape(-1, n_bins, 1)\n",
        "    X_test = X_test.reshape(-1, n_bins, 1)\n",
        "\n",
        "    metadata_test = metadata.iloc[idx_test].reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\nFinal - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "    print(f\"Train dist: 0={( y_train==0).sum()}, 1={(y_train==1).sum()}\")\n",
        "\n",
        "    # Return standardized test for model input, but also return the standardized\n",
        "    # copy (X_test_orig) so we can inverse-transform for plotting with error bars.\n",
        "    return X_train, X_test, y_train, y_test, metadata_test, X_test.copy(), X_err_test, scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e4e6b5",
      "metadata": {
        "id": "d0e4e6b5"
      },
      "source": [
        "## 6. A Simpler 1D CNN (to curb overfitting)\n",
        "\n",
        "A compact ConvNet with **BatchNorm**, **Dropout**, and **Global Average Pooling** is often enough for\n",
        "noisy, small-ish 1D signals. We also add mild L2 on the dense layers. The goal is a strong baseline\n",
        "that generalizes well, not a gigantic model that memorizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "c42e5a33",
      "metadata": {
        "id": "c42e5a33"
      },
      "outputs": [],
      "source": [
        "def build_simple_cnn(n_bins=1000):\n",
        "    \"\"\"Simpler CNN to prevent overfitting on small datasets.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING SIMPLIFIED CNN\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "\n",
        "        # Feature extraction\n",
        "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv1D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        # Classification head\n",
        "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=3, alpha=0.9),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "    print(\"\\nUsing Focal Loss (gamma=3, alpha=0.9)\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28417447",
      "metadata": {
        "id": "28417447"
      },
      "source": [
        "## 7. Training with AUC Monitoring, Early Stopping & LR Scheduling\n",
        "\n",
        "We monitor **validation AUC** (not accuracy) and:\n",
        "\n",
        "- **EarlyStopping** on `val_auc` with patience to stop when progress stalls.  \n",
        "- **ReduceLROnPlateau** to gently lower the LR when AUC plateaus.  \n",
        "- **ModelCheckpoint** to persist the best model by AUC.\n",
        "\n",
        "> Tip: If your dataset is *very* small, increase dropout and/or reduce dense layers further.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "799553e8",
      "metadata": {
        "id": "799553e8"
      },
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=100):\n",
        "    \"\"\"Train the model with AUC-centric callbacks.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Directory OUTSIDE this notebook\n",
        "    results_dir = \"../assignment2_taskF_results\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_auc',\n",
        "            patience=20,\n",
        "            restore_best_weights=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_auc',\n",
        "            factor=0.5,\n",
        "            patience=8,\n",
        "            min_lr=1e-7,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            os.path.join(results_dir, 'best_model_final.keras'),\n",
        "            monitor='val_auc',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2fd997b",
      "metadata": {
        "id": "a2fd997b"
      },
      "source": [
        "## 8. Evaluation with **Optimal Threshold** (don’t default to 0.5)\n",
        "\n",
        "The default threshold (0.5) is rarely optimal with imbalanced data.  \n",
        "We compute ROC, then choose the threshold that maximizes **Youden’s J** (\\(\\mathrm{TPR} - \\mathrm{FPR}\\)).\n",
        "We report both the default and the optimal settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b85e7698",
      "metadata": {
        "id": "b85e7698"
      },
      "outputs": [],
      "source": [
        "def evaluate_with_optimal_threshold(model, X_test, y_test):\n",
        "    \"\"\"Find an optimal threshold from ROC (Youden's J) and evaluate.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"THRESHOLD OPTIMIZATION & EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "    # Youden's J statistic\n",
        "    j_scores = tpr - fpr\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (default=0.5)\")\n",
        "    print(f\"  At this threshold: TPR={tpr[optimal_idx]:.4f}, FPR={fpr[optimal_idx]:.4f}\")\n",
        "\n",
        "    # Predictions with optimal vs default thresholds\n",
        "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "    y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
        "\n",
        "    # Metrics\n",
        "    acc_optimal = accuracy_score(y_test, y_pred_optimal)\n",
        "    acc_default = accuracy_score(y_test, y_pred_default)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    print(\"\\nResults:\")\n",
        "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
        "    print(f\"  Accuracy (default threshold=0.5): {acc_default:.4f} ({acc_default*100:.2f}%)\")\n",
        "    print(f\"  Accuracy (optimal threshold={optimal_threshold:.4f}): {acc_optimal:.4f} ({acc_optimal*100:.2f}%)\")\n",
        "\n",
        "    print(\"\\nWith optimal threshold:\")\n",
        "    print(classification_report(y_test, y_pred_optimal,\n",
        "                                target_names=['Non-Planet', 'Planet'],\n",
        "                                digits=4,\n",
        "                                zero_division=0))\n",
        "\n",
        "    print(\"\\nPrediction distribution (optimal threshold):\")\n",
        "    print(f\"  Predicted 0: {(y_pred_optimal == 0).sum()}\")\n",
        "    print(f\"  Predicted 1: {(y_pred_optimal == 1).sum()}\")\n",
        "    print(\"True distribution:\")\n",
        "    print(f\"  True 0: {(y_test == 0).sum()}\")\n",
        "    print(f\"  True 1: {(y_test == 1).sum()}\")\n",
        "\n",
        "    return y_pred_optimal, y_pred_proba, optimal_threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1529af",
      "metadata": {
        "id": "3e1529af"
      },
      "source": [
        "## 9. Visualization (Matplotlib-only)\n",
        "\n",
        "We save:\n",
        "- **Confusion matrix** (`confusion_matrix_final.png`) with counts and percentages.  \n",
        "- **Training curves** (`training_history_final.png`).  \n",
        "- **Sample light curves with predictions** (`sample_lightcurves_predictions.png`).\n",
        "\n",
        "> We use **Matplotlib** exclusively to minimize dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7ce2d06d",
      "metadata": {
        "id": "7ce2d06d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, y_pred_proba,\n",
        "                                      metadata_test, scaler, threshold, n_samples=6,\n",
        "                                      save_path=None):\n",
        "    \"\"\"Plot light curves with error bars and prediction info; save to file.\"\"\"\n",
        "\n",
        "    # Create results directory\n",
        "    results_dir = \"../assignment2_taskF_results\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    if save_path is None:\n",
        "        save_path = os.path.join(results_dir, \"sample_lightcurves_predictions.png\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"PLOTTING LIGHTCURVES WITH PREDICTIONS (n={n_samples})\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    n_samples = min(n_samples, len(X_test_orig))\n",
        "\n",
        "    # Select diverse samples: correct/incorrect for both classes\n",
        "    correct_planet = np.where((y_test == 1) & (y_pred == 1))[0]\n",
        "    incorrect_planet = np.where((y_test == 1) & (y_pred == 0))[0]\n",
        "    correct_nonplanet = np.where((y_test == 0) & (y_pred == 0))[0]\n",
        "    incorrect_nonplanet = np.where((y_test == 0) & (y_pred == 1))[0]\n",
        "\n",
        "    selected_idx = []\n",
        "    per_category = max(1, n_samples // 4)\n",
        "\n",
        "    for idx_list in [correct_planet, incorrect_planet, correct_nonplanet, incorrect_nonplanet]:\n",
        "        if len(idx_list) > 0:\n",
        "            n_select = min(per_category, len(idx_list))\n",
        "            selected_idx.extend(np.random.choice(idx_list, n_select, replace=False))\n",
        "\n",
        "    while len(selected_idx) < n_samples:\n",
        "        remaining = list(set(range(len(y_test))) - set(selected_idx))\n",
        "        if remaining:\n",
        "            selected_idx.append(np.random.choice(remaining))\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    selected_idx = np.array(selected_idx[:n_samples])\n",
        "\n",
        "    # Figure layout\n",
        "    n_cols = 2\n",
        "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
        "    if n_samples == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for plot_i, idx in enumerate(selected_idx):\n",
        "        ax = axes[plot_i]\n",
        "\n",
        "        flux_norm = X_test_orig[idx].flatten()\n",
        "        flux_err = X_err_test[idx]\n",
        "        flux_original = scaler.inverse_transform(flux_norm.reshape(1, -1)).flatten()\n",
        "\n",
        "        time_bins = np.arange(len(flux_original))\n",
        "\n",
        "        # Metadata\n",
        "        toi_name = metadata_test.loc[idx, 'toi_name']\n",
        "        tic = metadata_test.loc[idx, 'tic']\n",
        "        disp = metadata_test.loc[idx, 'disp']\n",
        "        sector = metadata_test.loc[idx, 'sector']\n",
        "\n",
        "        true_label = y_test[idx]\n",
        "        pred_label = y_pred[idx]\n",
        "        pred_prob = y_pred_proba[idx]\n",
        "\n",
        "        is_correct = (true_label == pred_label)\n",
        "        true_str = 'Transit' if true_label == 1 else 'Non-Transit'\n",
        "        pred_str = 'Transit' if pred_label == 1 else 'Non-Transit'\n",
        "\n",
        "        ax.errorbar(time_bins, flux_original, yerr=flux_err, fmt='o', markersize=2,\n",
        "                    ecolor='gray', elinewidth=0.5, capsize=0, alpha=0.6, label='Data')\n",
        "\n",
        "        baseline = np.median(flux_original)\n",
        "        ax.axhline(baseline, linestyle='--', linewidth=1, alpha=0.7, label='Baseline')\n",
        "\n",
        "        ax.set_xlabel('Time Bin', fontsize=10, fontweight='bold')\n",
        "        ax.set_ylabel('Flux (original scale)', fontsize=10, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(loc='upper right', fontsize=8)\n",
        "\n",
        "        status_symbol = '✓' if is_correct else '✗'\n",
        "        color = 'green' if is_correct else 'red'\n",
        "        title = (f'TOI {toi_name} (TIC {tic}, {disp}) - TESS Sector {sector}\\n'\n",
        "                 f'True: {true_str} | Pred: {pred_str} (p={pred_prob:.3f}) {status_symbol}')\n",
        "        ax.set_title(title, fontsize=10, fontweight='bold', color=color, pad=10)\n",
        "\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor(color)\n",
        "            spine.set_linewidth(2.0)\n",
        "\n",
        "    for j in range(n_samples, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.suptitle(f'Sample Light-curve Predictions (Threshold={threshold:.3f})',\n",
        "                 fontsize=14, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=None, X_err_test=None, scaler=None):\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Directory for results\n",
        "    results_dir = \"../assignment2_taskF_results\"\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # --- Confusion matrix ---\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(2),\n",
        "           yticks=np.arange(2),\n",
        "           xticklabels=['Non-Planet', 'Planet'],\n",
        "           yticklabels=['Non-Planet', 'Planet'],\n",
        "           xlabel='Predicted', ylabel='True',\n",
        "           title=f'Confusion Matrix (threshold={threshold:.3f})')\n",
        "\n",
        "    total = cm.sum()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            count = cm[i, j]\n",
        "            pct = (count / total * 100) if total > 0 else 0.0\n",
        "            ax.text(j, i, f\"{count}\\n({pct:.1f}%)\", ha='center', va='center', color='black', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    cm_path = os.path.join(results_dir, 'confusion_matrix_final.png')\n",
        "    plt.savefig(cm_path, dpi=300)\n",
        "    print(f\"Saved: {cm_path}\")\n",
        "    plt.close()\n",
        "\n",
        "    # --- Training history ---\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    metrics = [('loss', 'Loss'), ('accuracy', 'Accuracy'),\n",
        "               ('auc', 'AUC'), ('recall', 'Recall')]\n",
        "\n",
        "    for idx, (metric, title) in enumerate(metrics):\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        if metric in history.history and f'val_{metric}' in history.history:\n",
        "            ax.plot(history.history[metric], label='Train', linewidth=2)\n",
        "            ax.plot(history.history[f'val_{metric}'], label='Val', linewidth=2)\n",
        "            ax.set_xlabel('Epoch')\n",
        "            ax.set_ylabel(title)\n",
        "            ax.set_title(f'{title} vs Epoch', fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Training History - Final Model', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    hist_path = os.path.join(results_dir, 'training_history_final.png')\n",
        "    plt.savefig(hist_path, dpi=300)\n",
        "    print(f\"Saved: {hist_path}\")\n",
        "    plt.close()\n",
        "\n",
        "    # --- Light curves ---\n",
        "    if X_test_orig is not None and X_err_test is not None and scaler is not None:\n",
        "        plot_lightcurves_with_predictions(\n",
        "            X_test_orig, X_err_test, y_test, y_pred,\n",
        "            y_pred_proba, metadata_test, scaler, threshold,\n",
        "            n_samples=6,\n",
        "            save_path=os.path.join(results_dir, \"sample_lightcurves_predictions.png\")\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b561a755",
      "metadata": {
        "id": "b561a755"
      },
      "source": [
        "## 10. Run the Pipeline\n",
        "\n",
        "You can run the following cells **step by step**, or use the **end-to-end** cell.\n",
        "\n",
        "> If your CSV isn’t called `tess_data.csv`, change `CSV_PATH` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "053ea574",
      "metadata": {
        "id": "053ea574"
      },
      "outputs": [],
      "source": [
        "# Path to your dataset\n",
        "CSV_PATH = 'tess_data.csv'   # <- change me if needed\n",
        "N_BINS = 1000                # number of flux bins/columns per sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "bdfd93e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "bdfd93e1",
        "outputId": "679904df-7df3-4f07-9aa9-06b4e42138e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATA\n",
            "======================================================================\n",
            "Dataset: 944 samples\n",
            "\n",
            "Original distribution:\n",
            "  Class 0: 472, Class 1: 472\n",
            "  Ratio: 1.00:1\n",
            "\n",
            "Initial split - Train: 755, Test: 189\n",
            "\n",
            "======================================================================\n",
            "CREATING BALANCED DATASET\n",
            "======================================================================\n",
            "Original - Class 0: 377, Class 1: 378\n",
            "Balanced - Class 0: 350, Class 1: 350\n",
            "\n",
            "======================================================================\n",
            "STANDARDIZATION\n",
            "======================================================================\n",
            "Train: mean=0.000000, std=1.000000\n",
            "Test:  mean=-0.000855, std=0.434145\n",
            "\n",
            "Final - X_train: (700, 1000, 1), X_test: (189, 1000, 1)\n",
            "Train dist: 0=350, 1=350\n"
          ]
        }
      ],
      "source": [
        "# 1) Load and prepare data\n",
        "X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "    csv_path=CSV_PATH, n_bins=N_BINS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "8e5abe27",
      "metadata": {
        "id": "8e5abe27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING SIMPLIFIED CNN\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,249</span> (1.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,249\u001b[0m (1.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420,353</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420,353\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Focal Loss (gamma=3, alpha=0.9)\n"
          ]
        }
      ],
      "source": [
        "# 2) Build model\n",
        "model = build_simple_cnn(n_bins=N_BINS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "9d20cabc",
      "metadata": {
        "id": "9d20cabc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.4929 - auc: 0.4186 - loss: 0.8510 - precision: 0.5105 - recall: 0.8344\n",
            "Epoch 1: val_auc improved from None to 0.53819, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 262ms/step - accuracy: 0.4914 - auc: 0.4140 - loss: 0.8080 - precision: 0.4954 - recall: 0.9286 - val_accuracy: 0.4974 - val_auc: 0.5382 - val_loss: 0.7264 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5296 - auc: 0.4905 - loss: 0.6914 - precision: 0.5239 - recall: 0.9852\n",
            "Epoch 2: val_auc did not improve from 0.53819\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.5086 - auc: 0.4705 - loss: 0.6622 - precision: 0.5044 - recall: 0.9829 - val_accuracy: 0.4974 - val_auc: 0.5382 - val_loss: 0.5935 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5335 - auc: 0.5469 - loss: 0.5695 - precision: 0.5258 - recall: 0.9940\n",
            "Epoch 3: val_auc improved from 0.53819 to 0.54647, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.5143 - auc: 0.5361 - loss: 0.5461 - precision: 0.5073 - recall: 0.9914 - val_accuracy: 0.4974 - val_auc: 0.5465 - val_loss: 0.4927 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.5275 - auc: 0.6062 - loss: 0.4745 - precision: 0.5227 - recall: 0.9968\n",
            "Epoch 4: val_auc improved from 0.54647 to 0.55218, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.5129 - auc: 0.6100 - loss: 0.4543 - precision: 0.5066 - recall: 0.9943 - val_accuracy: 0.4974 - val_auc: 0.5522 - val_loss: 0.4117 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5368 - auc: 0.6673 - loss: 0.3941 - precision: 0.5278 - recall: 0.9955\n",
            "Epoch 5: val_auc improved from 0.55218 to 0.58516, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.5143 - auc: 0.6597 - loss: 0.3779 - precision: 0.5073 - recall: 0.9943 - val_accuracy: 0.4974 - val_auc: 0.5852 - val_loss: 0.3453 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5314 - auc: 0.6856 - loss: 0.3290 - precision: 0.5248 - recall: 0.9933\n",
            "Epoch 6: val_auc improved from 0.58516 to 0.59518, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 0.5100 - auc: 0.6920 - loss: 0.3158 - precision: 0.5051 - recall: 0.9914 - val_accuracy: 0.4974 - val_auc: 0.5952 - val_loss: 0.2909 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5241 - auc: 0.7089 - loss: 0.2762 - precision: 0.5208 - recall: 0.9978\n",
            "Epoch 7: val_auc improved from 0.59518 to 0.74496, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.5086 - auc: 0.7193 - loss: 0.2653 - precision: 0.5043 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.7450 - val_loss: 0.2463 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5451 - auc: 0.7480 - loss: 0.2320 - precision: 0.5323 - recall: 0.9997\n",
            "Epoch 8: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.5229 - auc: 0.7488 - loss: 0.2235 - precision: 0.5117 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.5869 - val_loss: 0.2089 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.5442 - auc: 0.7685 - loss: 0.1967 - precision: 0.5319 - recall: 0.9978\n",
            "Epoch 9: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.5186 - auc: 0.7598 - loss: 0.1899 - precision: 0.5095 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.6116 - val_loss: 0.1786 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.5315 - auc: 0.7660 - loss: 0.1682 - precision: 0.5246 - recall: 0.9989\n",
            "Epoch 10: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.5157 - auc: 0.7728 - loss: 0.1623 - precision: 0.5080 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.5371 - val_loss: 0.1531 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5442 - auc: 0.7489 - loss: 0.1449 - precision: 0.5319 - recall: 0.9978\n",
            "Epoch 11: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.5200 - auc: 0.7685 - loss: 0.1400 - precision: 0.5102 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.5775 - val_loss: 0.1327 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5290 - auc: 0.7817 - loss: 0.1251 - precision: 0.5234 - recall: 1.0000\n",
            "Epoch 12: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.5143 - auc: 0.7910 - loss: 0.1211 - precision: 0.5072 - recall: 1.0000 - val_accuracy: 0.4974 - val_auc: 0.5386 - val_loss: 0.1155 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5446 - auc: 0.7603 - loss: 0.1104 - precision: 0.5322 - recall: 0.9928\n",
            "Epoch 13: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5214 - auc: 0.7710 - loss: 0.1065 - precision: 0.5110 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.5812 - val_loss: 0.1019 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5475 - auc: 0.7778 - loss: 0.0962 - precision: 0.5335 - recall: 1.0000\n",
            "Epoch 14: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.5243 - auc: 0.7859 - loss: 0.0934 - precision: 0.5124 - recall: 1.0000 - val_accuracy: 0.4974 - val_auc: 0.6035 - val_loss: 0.0911 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5476 - auc: 0.7780 - loss: 0.0855 - precision: 0.5342 - recall: 0.9906\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 15: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.5171 - auc: 0.7839 - loss: 0.0832 - precision: 0.5088 - recall: 0.9943 - val_accuracy: 0.4974 - val_auc: 0.7286 - val_loss: 0.0823 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5228 - auc: 0.8052 - loss: 0.0767 - precision: 0.5200 - recall: 1.0000\n",
            "Epoch 16: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.5114 - auc: 0.8086 - loss: 0.0755 - precision: 0.5058 - recall: 1.0000 - val_accuracy: 0.4974 - val_auc: 0.7246 - val_loss: 0.0771 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5385 - auc: 0.8017 - loss: 0.0727 - precision: 0.5288 - recall: 0.9917\n",
            "Epoch 17: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5214 - auc: 0.8100 - loss: 0.0715 - precision: 0.5110 - recall: 0.9943 - val_accuracy: 0.4974 - val_auc: 0.6994 - val_loss: 0.0731 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5399 - auc: 0.8131 - loss: 0.0687 - precision: 0.5294 - recall: 0.9917\n",
            "Epoch 18: val_auc did not improve from 0.74496\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5257 - auc: 0.8180 - loss: 0.0675 - precision: 0.5133 - recall: 0.9943 - val_accuracy: 0.4974 - val_auc: 0.7445 - val_loss: 0.0692 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5550 - auc: 0.7914 - loss: 0.0656 - precision: 0.5380 - recall: 0.9928\n",
            "Epoch 19: val_auc improved from 0.74496 to 0.74933, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5343 - auc: 0.8059 - loss: 0.0643 - precision: 0.5178 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.7493 - val_loss: 0.0653 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5474 - auc: 0.7958 - loss: 0.0624 - precision: 0.5337 - recall: 0.9895\n",
            "Epoch 20: val_auc did not improve from 0.74933\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.5314 - auc: 0.8104 - loss: 0.0611 - precision: 0.5164 - recall: 0.9914 - val_accuracy: 0.4974 - val_auc: 0.7366 - val_loss: 0.0621 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5511 - auc: 0.8121 - loss: 0.0587 - precision: 0.5356 - recall: 0.9989\n",
            "Epoch 21: val_auc did not improve from 0.74933\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5314 - auc: 0.8229 - loss: 0.0577 - precision: 0.5163 - recall: 0.9971 - val_accuracy: 0.4974 - val_auc: 0.7259 - val_loss: 0.0596 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5479 - auc: 0.8073 - loss: 0.0561 - precision: 0.5339 - recall: 0.9906\n",
            "Epoch 22: val_auc did not improve from 0.74933\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5357 - auc: 0.8143 - loss: 0.0550 - precision: 0.5186 - recall: 0.9943 - val_accuracy: 0.4974 - val_auc: 0.7371 - val_loss: 0.0567 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5524 - auc: 0.7939 - loss: 0.0539 - precision: 0.5364 - recall: 0.9945\n",
            "Epoch 23: val_auc did not improve from 0.74933\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.5314 - auc: 0.8101 - loss: 0.0526 - precision: 0.5163 - recall: 0.9943 - val_accuracy: 0.5026 - val_auc: 0.7227 - val_loss: 0.0546 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5530 - auc: 0.8074 - loss: 0.0511 - precision: 0.5366 - recall: 0.9917\n",
            "Epoch 24: val_auc did not improve from 0.74933\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5457 - auc: 0.8147 - loss: 0.0503 - precision: 0.5241 - recall: 0.9943 - val_accuracy: 0.5026 - val_auc: 0.7375 - val_loss: 0.0530 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5611 - auc: 0.8210 - loss: 0.0483 - precision: 0.5413 - recall: 0.9900\n",
            "Epoch 25: val_auc did not improve from 0.74933\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5443 - auc: 0.8223 - loss: 0.0477 - precision: 0.5233 - recall: 0.9943 - val_accuracy: 0.5026 - val_auc: 0.7015 - val_loss: 0.0516 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5666 - auc: 0.8123 - loss: 0.0466 - precision: 0.5447 - recall: 0.9906\n",
            "Epoch 26: val_auc improved from 0.74933 to 0.77273, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.5400 - auc: 0.8236 - loss: 0.0457 - precision: 0.5210 - recall: 0.9943 - val_accuracy: 0.5026 - val_auc: 0.7727 - val_loss: 0.0494 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5502 - auc: 0.7978 - loss: 0.0451 - precision: 0.5352 - recall: 0.9917\n",
            "Epoch 27: val_auc did not improve from 0.77273\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.5357 - auc: 0.8126 - loss: 0.0441 - precision: 0.5186 - recall: 0.9943 - val_accuracy: 0.5026 - val_auc: 0.6935 - val_loss: 0.0477 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5485 - auc: 0.8163 - loss: 0.0428 - precision: 0.5343 - recall: 0.9906\n",
            "Epoch 28: val_auc improved from 0.77273 to 0.78135, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.5314 - auc: 0.8261 - loss: 0.0419 - precision: 0.5163 - recall: 0.9943 - val_accuracy: 0.5079 - val_auc: 0.7814 - val_loss: 0.0464 - val_precision: 0.5027 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5474 - auc: 0.8090 - loss: 0.0415 - precision: 0.5338 - recall: 0.9883\n",
            "Epoch 29: val_auc did not improve from 0.78135\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5357 - auc: 0.8193 - loss: 0.0406 - precision: 0.5186 - recall: 0.9943 - val_accuracy: 0.5185 - val_auc: 0.7731 - val_loss: 0.0441 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5537 - auc: 0.8264 - loss: 0.0393 - precision: 0.5371 - recall: 0.9900\n",
            "Epoch 30: val_auc did not improve from 0.78135\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.5471 - auc: 0.8258 - loss: 0.0389 - precision: 0.5249 - recall: 0.9943 - val_accuracy: 0.5238 - val_auc: 0.7696 - val_loss: 0.0423 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5727 - auc: 0.8236 - loss: 0.0380 - precision: 0.5487 - recall: 0.9900\n",
            "Epoch 31: val_auc did not improve from 0.78135\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5500 - auc: 0.8328 - loss: 0.0373 - precision: 0.5265 - recall: 0.9943 - val_accuracy: 0.5344 - val_auc: 0.7277 - val_loss: 0.0416 - val_precision: 0.5165 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6043 - auc: 0.8164 - loss: 0.0367 - precision: 0.5679 - recall: 0.9928\n",
            "Epoch 32: val_auc improved from 0.78135 to 0.78947, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.5771 - auc: 0.8196 - loss: 0.0361 - precision: 0.5419 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.7895 - val_loss: 0.0395 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.5882 - auc: 0.8291 - loss: 0.0354 - precision: 0.5573 - recall: 0.9920\n",
            "Epoch 33: val_auc improved from 0.78947 to 0.84127, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.5771 - auc: 0.8352 - loss: 0.0347 - precision: 0.5421 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.8413 - val_loss: 0.0374 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5941 - auc: 0.8236 - loss: 0.0348 - precision: 0.5613 - recall: 0.9928\n",
            "Epoch 34: val_auc improved from 0.84127 to 0.84339, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.5729 - auc: 0.8311 - loss: 0.0339 - precision: 0.5394 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8434 - val_loss: 0.0365 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5864 - auc: 0.8135 - loss: 0.0338 - precision: 0.5564 - recall: 0.9874\n",
            "Epoch 35: val_auc improved from 0.84339 to 0.86254, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.5829 - auc: 0.8264 - loss: 0.0328 - precision: 0.5457 - recall: 0.9886 - val_accuracy: 0.5291 - val_auc: 0.8625 - val_loss: 0.0350 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5970 - auc: 0.8076 - loss: 0.0328 - precision: 0.5636 - recall: 0.9845\n",
            "Epoch 36: val_auc did not improve from 0.86254\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.5714 - auc: 0.8239 - loss: 0.0321 - precision: 0.5389 - recall: 0.9886 - val_accuracy: 0.5556 - val_auc: 0.7887 - val_loss: 0.0350 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6020 - auc: 0.8301 - loss: 0.0314 - precision: 0.5664 - recall: 0.9845\n",
            "Epoch 37: val_auc improved from 0.86254 to 0.86825, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.5886 - auc: 0.8416 - loss: 0.0306 - precision: 0.5492 - recall: 0.9886 - val_accuracy: 0.5503 - val_auc: 0.8683 - val_loss: 0.0320 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6019 - auc: 0.8174 - loss: 0.0308 - precision: 0.5661 - recall: 0.9890\n",
            "Epoch 38: val_auc did not improve from 0.86825\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.5843 - auc: 0.8214 - loss: 0.0303 - precision: 0.5465 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8438 - val_loss: 0.0326 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5788 - auc: 0.8205 - loss: 0.0299 - precision: 0.5524 - recall: 0.9793\n",
            "Epoch 39: val_auc did not improve from 0.86825\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.5771 - auc: 0.8349 - loss: 0.0291 - precision: 0.5423 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.7419 - val_loss: 0.0333 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6004 - auc: 0.8348 - loss: 0.0287 - precision: 0.5651 - recall: 0.9883\n",
            "Epoch 40: val_auc did not improve from 0.86825\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5914 - auc: 0.8433 - loss: 0.0281 - precision: 0.5506 - recall: 0.9943 - val_accuracy: 0.5556 - val_auc: 0.8516 - val_loss: 0.0325 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5889 - auc: 0.8244 - loss: 0.0284 - precision: 0.5589 - recall: 0.9780\n",
            "Epoch 41: val_auc did not improve from 0.86825\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.5886 - auc: 0.8353 - loss: 0.0277 - precision: 0.5492 - recall: 0.9886 - val_accuracy: 0.5450 - val_auc: 0.8635 - val_loss: 0.0292 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6023 - auc: 0.8240 - loss: 0.0280 - precision: 0.5667 - recall: 0.9810\n",
            "Epoch 42: val_auc did not improve from 0.86825\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.6014 - auc: 0.8399 - loss: 0.0270 - precision: 0.5574 - recall: 0.9857 - val_accuracy: 0.5661 - val_auc: 0.8620 - val_loss: 0.0288 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6260 - auc: 0.8180 - loss: 0.0277 - precision: 0.5822 - recall: 0.9899\n",
            "Epoch 43: val_auc improved from 0.86825 to 0.88096, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.5971 - auc: 0.8308 - loss: 0.0269 - precision: 0.5545 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.8810 - val_loss: 0.0275 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6008 - auc: 0.8261 - loss: 0.0266 - precision: 0.5657 - recall: 0.9910\n",
            "Epoch 44: val_auc improved from 0.88096 to 0.89043, saving model to ../assignment2_taskF_results/best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.5843 - auc: 0.8444 - loss: 0.0259 - precision: 0.5465 - recall: 0.9914 - val_accuracy: 0.5661 - val_auc: 0.8904 - val_loss: 0.0262 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.6119 - auc: 0.8395 - loss: 0.0260 - precision: 0.5740 - recall: 0.9776\n",
            "Epoch 45: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.5986 - auc: 0.8336 - loss: 0.0256 - precision: 0.5554 - recall: 0.9886 - val_accuracy: 0.5661 - val_auc: 0.8611 - val_loss: 0.0273 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6159 - auc: 0.8365 - loss: 0.0256 - precision: 0.5753 - recall: 0.9849\n",
            "Epoch 46: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5971 - auc: 0.8461 - loss: 0.0247 - precision: 0.5545 - recall: 0.9886 - val_accuracy: 0.5556 - val_auc: 0.8768 - val_loss: 0.0265 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6126 - auc: 0.8328 - loss: 0.0251 - precision: 0.5736 - recall: 0.9831\n",
            "Epoch 47: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.6071 - auc: 0.8480 - loss: 0.0241 - precision: 0.5604 - recall: 0.9943 - val_accuracy: 0.5661 - val_auc: 0.8631 - val_loss: 0.0264 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.6065 - auc: 0.8423 - loss: 0.0245 - precision: 0.5695 - recall: 0.9793\n",
            "Epoch 48: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.6000 - auc: 0.8457 - loss: 0.0240 - precision: 0.5565 - recall: 0.9857 - val_accuracy: 0.5608 - val_auc: 0.8477 - val_loss: 0.0279 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6105 - auc: 0.8331 - loss: 0.0243 - precision: 0.5716 - recall: 0.9890\n",
            "Epoch 49: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5986 - auc: 0.8410 - loss: 0.0239 - precision: 0.5557 - recall: 0.9829 - val_accuracy: 0.5608 - val_auc: 0.8494 - val_loss: 0.0266 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6168 - auc: 0.8135 - loss: 0.0251 - precision: 0.5784 - recall: 0.9714\n",
            "Epoch 50: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.5971 - auc: 0.8205 - loss: 0.0242 - precision: 0.5545 - recall: 0.9886 - val_accuracy: 0.5556 - val_auc: 0.8582 - val_loss: 0.0256 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6002 - auc: 0.8476 - loss: 0.0231 - precision: 0.5649 - recall: 0.9900\n",
            "Epoch 51: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.5829 - auc: 0.8502 - loss: 0.0227 - precision: 0.5455 - recall: 0.9943 - val_accuracy: 0.5661 - val_auc: 0.8447 - val_loss: 0.0256 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.6351 - auc: 0.8570 - loss: 0.0227 - precision: 0.5891 - recall: 0.9845\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 52: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.6100 - auc: 0.8584 - loss: 0.0222 - precision: 0.5626 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.7517 - val_loss: 0.0276 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6413 - auc: 0.8413 - loss: 0.0230 - precision: 0.5944 - recall: 0.9718\n",
            "Epoch 53: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.6200 - auc: 0.8455 - loss: 0.0226 - precision: 0.5695 - recall: 0.9829 - val_accuracy: 0.5608 - val_auc: 0.7760 - val_loss: 0.0273 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6424 - auc: 0.8531 - loss: 0.0221 - precision: 0.5927 - recall: 0.9917\n",
            "Epoch 54: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.6157 - auc: 0.8619 - loss: 0.0218 - precision: 0.5659 - recall: 0.9943 - val_accuracy: 0.5608 - val_auc: 0.7669 - val_loss: 0.0271 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6362 - auc: 0.8541 - loss: 0.0222 - precision: 0.5893 - recall: 0.9806\n",
            "Epoch 55: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.6114 - auc: 0.8614 - loss: 0.0218 - precision: 0.5637 - recall: 0.9857 - val_accuracy: 0.5608 - val_auc: 0.7651 - val_loss: 0.0267 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6452 - auc: 0.8602 - loss: 0.0215 - precision: 0.5944 - recall: 0.9900\n",
            "Epoch 56: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.6329 - auc: 0.8669 - loss: 0.0211 - precision: 0.5771 - recall: 0.9943 - val_accuracy: 0.5661 - val_auc: 0.8641 - val_loss: 0.0242 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6388 - auc: 0.8427 - loss: 0.0224 - precision: 0.5926 - recall: 0.9726\n",
            "Epoch 57: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.6314 - auc: 0.8568 - loss: 0.0214 - precision: 0.5767 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.8418 - val_loss: 0.0258 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.6342 - auc: 0.8409 - loss: 0.0223 - precision: 0.5889 - recall: 0.9749\n",
            "Epoch 58: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.6229 - auc: 0.8469 - loss: 0.0217 - precision: 0.5712 - recall: 0.9857 - val_accuracy: 0.5608 - val_auc: 0.8218 - val_loss: 0.0259 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.6306 - auc: 0.8417 - loss: 0.0218 - precision: 0.5870 - recall: 0.9729\n",
            "Epoch 59: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.6057 - auc: 0.8510 - loss: 0.0213 - precision: 0.5601 - recall: 0.9857 - val_accuracy: 0.5661 - val_auc: 0.8452 - val_loss: 0.0249 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6564 - auc: 0.8638 - loss: 0.0208 - precision: 0.6018 - recall: 0.9920\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 60: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.6414 - auc: 0.8719 - loss: 0.0203 - precision: 0.5829 - recall: 0.9943 - val_accuracy: 0.5608 - val_auc: 0.7875 - val_loss: 0.0266 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6442 - auc: 0.8527 - loss: 0.0215 - precision: 0.5941 - recall: 0.9845\n",
            "Epoch 61: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.6357 - auc: 0.8623 - loss: 0.0209 - precision: 0.5796 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.7175 - val_loss: 0.0273 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 62/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6482 - auc: 0.8512 - loss: 0.0209 - precision: 0.5967 - recall: 0.9875\n",
            "Epoch 62: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.6386 - auc: 0.8591 - loss: 0.0207 - precision: 0.5818 - recall: 0.9857 - val_accuracy: 0.5608 - val_auc: 0.7737 - val_loss: 0.0264 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 63/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.6154 - auc: 0.8456 - loss: 0.0218 - precision: 0.5756 - recall: 0.9750\n",
            "Epoch 63: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.6114 - auc: 0.8591 - loss: 0.0210 - precision: 0.5635 - recall: 0.9886 - val_accuracy: 0.5661 - val_auc: 0.7655 - val_loss: 0.0260 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 64/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6415 - auc: 0.8570 - loss: 0.0208 - precision: 0.5921 - recall: 0.9862\n",
            "Epoch 64: val_auc did not improve from 0.89043\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.6271 - auc: 0.8635 - loss: 0.0205 - precision: 0.5736 - recall: 0.9914 - val_accuracy: 0.5661 - val_auc: 0.8180 - val_loss: 0.0257 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 64: early stopping\n",
            "Restoring model weights from the end of the best epoch: 44.\n"
          ]
        }
      ],
      "source": [
        "# 3) Train\n",
        "history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "b0baecc6",
      "metadata": {
        "id": "b0baecc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x74ff786b0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\n",
            "Optimal threshold: 0.6204 (default=0.5)\n",
            "  At this threshold: TPR=0.8298, FPR=0.1263\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8895\n",
            "  Accuracy (default threshold=0.5): 0.5661 (56.61%)\n",
            "  Accuracy (optimal threshold=0.6204): 0.8519 (85.19%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8384    0.8737    0.8557        95\n",
            "      Planet     0.8667    0.8298    0.8478        94\n",
            "\n",
            "    accuracy                         0.8519       189\n",
            "   macro avg     0.8525    0.8517    0.8517       189\n",
            "weighted avg     0.8525    0.8519    0.8518       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 99\n",
            "  Predicted 1: 90\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n"
          ]
        }
      ],
      "source": [
        "# 4) Evaluate with optimal threshold\n",
        "y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "a6e0f6da",
      "metadata": {
        "id": "a6e0f6da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: ../assignment2_taskF_results/confusion_matrix_final.png\n",
            "Saved: ../assignment2_taskF_results/training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: ../assignment2_taskF_results/sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Key improvements:\n",
            "  ✓ Perfectly balanced training data\n",
            "  ✓ Focal loss for hard examples\n",
            "  ✓ Optimal threshold selection\n",
            "  ✓ AUC-focused optimization\n",
            "\n",
            "Files:\n",
            "  - ../assignment2_taskF_results/tess_model_final.keras\n",
            "  - ../assignment2_taskF_results/best_model_final.keras\n",
            "  - ../assignment2_taskF_results/optimal_threshold.npy\n",
            "  - ../assignment2_taskF_results/confusion_matrix_final.png\n",
            "  - ../assignment2_taskF_results/training_history_final.png\n",
            "  - ../assignment2_taskF_results/sample_lightcurves_predictions.png\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Ensure results directory exists\n",
        "results_dir = \"../assignment2_taskF_results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# 5) Visualize & save artifacts\n",
        "plot_all(\n",
        "    y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "    X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler\n",
        ")\n",
        "\n",
        "# Persist model and threshold\n",
        "model.save(os.path.join(results_dir, 'tess_model_final.keras'))\n",
        "np.save(os.path.join(results_dir, 'optimal_threshold.npy'), threshold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey improvements:\")\n",
        "print(\"  ✓ Perfectly balanced training data\")\n",
        "print(\"  ✓ Focal loss for hard examples\")\n",
        "print(\"  ✓ Optimal threshold selection\")\n",
        "print(\"  ✓ AUC-focused optimization\")\n",
        "print(\"\\nFiles:\")\n",
        "print(f\"  - {results_dir}/tess_model_final.keras\")\n",
        "print(f\"  - {results_dir}/best_model_final.keras\")\n",
        "print(f\"  - {results_dir}/optimal_threshold.npy\")\n",
        "print(f\"  - {results_dir}/confusion_matrix_final.png\")\n",
        "print(f\"  - {results_dir}/training_history_final.png\")\n",
        "print(f\"  - {results_dir}/sample_lightcurves_predictions.png\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797e9d45",
      "metadata": {
        "id": "797e9d45"
      },
      "source": [
        "## 11. (Optional) One-Click: Run Everything\n",
        "\n",
        "This cell wraps all steps into a single function for convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "42f938a4",
      "metadata": {
        "id": "42f938a4"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "        csv_path=CSV_PATH, n_bins=N_BINS\n",
        "    )\n",
        "    model = build_simple_cnn(n_bins=N_BINS)\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)\n",
        "    y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)\n",
        "    plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "    model.save('tess_model_final.keras')\n",
        "    np.save('optimal_threshold.npy', threshold)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nKey improvements:\")\n",
        "    print(\"  ✓ Perfectly balanced training data\")\n",
        "    print(\"  ✓ Focal loss for hard examples\")\n",
        "    print(\"  ✓ Optimal threshold selection\")\n",
        "    print(\"  ✓ AUC-focused optimization\")\n",
        "    print(\"\\nFiles:\")\n",
        "    print(\"  - tess_model_final.keras\")\n",
        "    print(\"  - best_model_final.keras\")\n",
        "    print(\"  - optimal_threshold.npy\")\n",
        "    print(\"  - confusion_matrix_final.png\")\n",
        "    print(\"  - training_history_final.png\")\n",
        "    print(\"  - sample_lightcurves_predictions.png\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Uncomment to run end-to-end:\n",
        "# main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NEr_97NTZjtO",
      "metadata": {
        "id": "NEr_97NTZjtO"
      },
      "source": [
        "## 12. Interpreting Results & Next Steps\n",
        "\n",
        "- **AUC-ROC** is the primary score during training. Inspect training curves to ensure you’re not overfitting.  \n",
        "- **Confusion matrix** with counts and percentages helps quantify trade-offs at the **optimal threshold**.  \n",
        "- **False positives** vs **false negatives**: use domain needs to decide how to tune `alpha`/`gamma` in focal loss or to move the threshold.\n",
        "\n",
        "**Ideas to try next**\n",
        "\n",
        "- Add **class-dependent augmentations** (e.g., transit-like dips for positives).  \n",
        "- Calibrate probabilities (e.g., **Platt scaling**, **isotonic regression**) for better decision thresholds.  \n",
        "- Incorporate additional channels (centroid motion, background, etc.) into a **multi-input** model.  \n",
        "- Use **cross-validation** on the training set to measure variability across folds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OtLX0_buZjtO",
      "metadata": {
        "id": "OtLX0_buZjtO"
      },
      "source": [
        "---\n",
        "\n",
        "### Appendix: Notes on Data Schema\n",
        "\n",
        "- Ensure your CSV contains **exactly** `n_bins` columns named `flux_0000 .. flux_{n_bins-1:04d}` and matching `flux_err_*` columns.\n",
        "- Metadata columns are optional for training but used for prettier plots.\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "- `ValueError: columns not found`: your CSV headers don’t match the expected names. Check `n_bins` and column prefixes.  \n",
        "- `CUDA out of memory`: reduce `batch_size`, or limit GPU memory; try the provided GPU memory-growth snippet.  \n",
        "- `AUC not improving`: try a bigger `samples_per_class`, more dropout, or adjust `gamma`/`alpha`.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "comp_astro25",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
